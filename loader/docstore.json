[[["98905345-65ee-4831-bc32-689ca5ff525c",{"pageContent":"Below is the unedited penultimate draft of:\n[scanned in by OCR: contains errors]\nSearle, John. R. (1980) Minds, brains, and programs. \nBehavioral and\nBrain Sciences 3 (3): 417-457\nThis is the unedited penultimate draft of a BBS target article that has been accepted for publication \n(Copyright 1980: Cambridge University Press \n/\n-- publication date provisional) and is \ncurrently being circulated for Open Peer Commentary. This preprint is for inspection only, to help \nprospective commentators decide whether or not they wish to prepare a formal commentary. Please do \nnot prepare a commentary unless you have received the hard copy, invitation, instructions and deadline \ninformation.\nU.K.\nU.S.\nFor information on becoming a commentator on this or other BBS target\narticles, write to:\nbbs@soton.ac.uk\nFor information about subscribing or purchasing offprints of the\npublished version, with commentaries \nand author's response, write to:\n (North America) or\n (All other countries).","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":1,"lines":{"from":1,"to":23}}}}],["8d793fdf-8a12-48ed-9eaf-2713cd80e442",{"pageContent":"bbs@soton.ac.uk\nFor information about subscribing or purchasing offprints of the\npublished version, with commentaries \nand author's response, write to:\n (North America) or\n (All other countries).\njournals_subscriptions@cup.org\njournals_marketing@cup.cam.ac.uk\nMINDS, BRAINS, AND PROGRAMS\nJohn R. Searle\nDepartment of Philosophy\nUniversity of California\nBerkeley, California. 94720\nsearle@cogsci.berkeley.edu\nAbstract\nThis article can be viewed as an attempt to explore the\nconsequences of two propositions. (1) Intentionality in \nhuman\nbeings (and animals) is a product of causal features of the brain I\nassume this is an empirical fact about \nthe actual causal relations\nbetween mental processes and brains It says simply that certain\nbrain processes are \nsufficient for intentionality. (2)\nInstantiating a computer program is never by itself a sufficient\ncondition of \nintentionality The main argument of this paper is\ndirected at establishing this claim The form of the argument is to","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":1,"lines":{"from":23,"to":50}}}}],["7eb2523c-1cfc-48ac-ab16-9ebc7f7d84c0",{"pageContent":"Instantiating a computer program is never by itself a sufficient\ncondition of \nintentionality The main argument of this paper is\ndirected at establishing this claim The form of the argument is to\nshow how a human agent could instantiate the program and still not\nhave the relevant intentionality. These two \npropositions have the\nfollowing consequences (3) The explanation of how the brain\nproduces intentionality \ncannot be that it does it by instantiating\na computer program. This is a strict logical consequence of 1 and\n2. (4) \nAny mechanism capable of producing intentionality must have\ncausal powers equal to those of the brain. This is \nmeant to be a\ntrivial consequence of 1. (5) Any attempt literally to create\nintentionality artificially (strong AI) \ncould not succeed just by\ndesigning programs but would have to duplicate the causal powers of\nthe human \nbrain. This follows from 2 and 4.\n\"Could a machine think?\" On the argument advanced here only a","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":1,"lines":{"from":50,"to":71}}}}],["63e259a1-aa58-4180-ba87-d4e106eff705",{"pageContent":"designing programs but would have to duplicate the causal powers of\nthe human \nbrain. This follows from 2 and 4.\n\"Could a machine think?\" On the argument advanced here only a\nmachine could think, and only very special \nkinds of machines,\nnamely brains and machines with internal causal powers equivalent\nto those of brains And \nthat is why strong AI has little to tell us\nabout thinking, since it is not about machines but about programs,\nand \nno program by itself is sufficient for thinking.\n7/14/03 6:14 PM\nMinds, Brains, and Programs\nPage 1 of 19\nhttp://www.bbsonline.org/documents/a/00/00/04/84/bbs00000484-00/bbs.searle2.html","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":1,"lines":{"from":71,"to":86}}}}],["cee7e636-2b11-4ed6-86ab-e02b5730f5ad",{"pageContent":"Keywords\nartificial intelligence, brain, intentionality, mind\nWhat psychological and philosophical significance should we attach to\nrecent efforts at computer simulations of \nhuman cognitive capacities?\nIn answering this question, I find it useful to distinguish what I will\ncall \"strong\" AI \nfrom \"weak\" or \"cautious\" AI (Artificial\nIntelligence). According to weak AI, the principal value of the\ncomputer \nin the study of the mind is that it gives us a very powerful\ntool. For example, it enables us to formulate and test \nhypotheses in a\nmore rigorous and precise fashion. But according to strong AI, the\ncomputer is not merely a \ntool in the study of the mind; rather, the\nappropriately programmed computer really is a mind, in the sense that\ncomputers given the right programs can be literally said to understand\nand have other cognitive states. In strong \nAI, because the programmed\ncomputer has cognitive states, the programs are not mere tools that\nenable us to","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":2,"lines":{"from":1,"to":22}}}}],["b4e8a985-c6e5-4c1e-abde-f54274e640c6",{"pageContent":"and have other cognitive states. In strong \nAI, because the programmed\ncomputer has cognitive states, the programs are not mere tools that\nenable us to \ntest psychological explanations; rather, the programs are\nthemselves the explanations.\nI have no objection to the claims of weak AI, at least as far as this\narticle is concerned. My discussion here will \nbe directed at the claims\nI have defined as those of strong AI, specifically the claim that the\nappropriately \nprogrammed computer literally has cognitive states and\nthat the programs thereby explain human cognition. \nWhen I hereafter\nrefer to AI, I have in mind the strong version, as expressed by these\ntwo claims.\nI will consider the work of Roger Schank and his colleagues at Yale\n(Schank & Abelson 1977), because I am \nmore familiar with it than I am\nwith any other similar claims, and because it provides a very clear\nexample of the \nsort of work I wish to examine. But nothing that follows","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":2,"lines":{"from":22,"to":43}}}}],["fba20dbb-8340-496d-882c-61590936dd75",{"pageContent":"more familiar with it than I am\nwith any other similar claims, and because it provides a very clear\nexample of the \nsort of work I wish to examine. But nothing that follows\ndepends upon the details of Schank's programs. The \nsame arguments would\napply to Winograd's SHRDLU (Winograd 1973), Weizenbaum's ELIZA\n(Weizenbaum \n1965), and indeed any Turing machine simulation of human\nmental phenomena.\nVery briefly, and leaving out the various details, one can describe\nSchank's program as follows: the aim of the \nprogram is to simulate the\nhuman ability to understand stories. It is characteristic of human\nbeings' story-\nunderstanding capacity that they can answer questions\nabout the story even though the information that they \ngive was never\nexplicitly stated in the story. Thus, for example, suppose you are\ngiven the following story:\n-A man went into a restaurant and ordered a hamburger. When the\nhamburger arrived it was burned to a crisp, \nand the man stormed out of","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":2,"lines":{"from":43,"to":65}}}}],["c9c358b9-3f48-4196-8065-32f0d091aa2e",{"pageContent":"given the following story:\n-A man went into a restaurant and ordered a hamburger. When the\nhamburger arrived it was burned to a crisp, \nand the man stormed out of\nthe restaurant angrily, without paying for the hamburger or leaving a\ntip.\" Now, if \nyou are asked -Did the man eat the hamburger?\" you will\npresumably answer, ' No, he did not.' Similarly, if \nyou are given the\nfollowing story: '-A man went into a restaurant and ordered a\nhamburger; when the \nhamburger came he was very pleased with it; and as\nhe left the restaurant he gave the waitress a large tip \nbefore paying\nhis bill,\" and you are asked the question, -Did the man eat the\nhamburger?,-' you will presumably \nanswer, -Yes, he ate the hamburger.\"\nNow Schank's machines can similarly answer questions about restaurants\nin this fashion. To do this, they have a -representation\" of the sort\nof information that human beings have about \nrestaurants, which enables\nthem to answer such questions as those above, given these sorts of","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":2,"lines":{"from":65,"to":86}}}}],["5c278deb-ddce-439d-80bc-89a8bb7f7ac7",{"pageContent":"of information that human beings have about \nrestaurants, which enables\nthem to answer such questions as those above, given these sorts of\nstories. When the \nmachine is given the story and then asked the\nquestion, the machine will print out answers of the sort that we \nwould\nexpect human beings to give if told similar stories. Partisans of\nstrong AI claim that in this question and \nanswer sequence the machine\nis not only simulating a human ability but also\n1.\nthat the machine can literally be said to understand the story and\nprovide the answers to questions, and\n7/14/03 6:14 PM\nMinds, Brains, and Programs\nPage 2 of 19\nhttp://www.bbsonline.org/documents/a/00/00/04/84/bbs00000484-00/bbs.searle2.html","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":2,"lines":{"from":86,"to":103}}}}],["57068be2-f86c-4547-8e2c-fe04579b901b",{"pageContent":"2.\nthat what the machine and its program do explains the human ability\nto understand the story and answer \nquestions about it.\nBoth claims seem to me to be totally unsupported by Schank's' work, as\nI will attempt to show in what follows.\nOne way to test any theory of the mind is to ask oneself what it would\nbe like if my mind actually worked on \nthe principles that the theory\nsays all minds work on. Let us apply this test to the Schank program\nwith the \nfollowing Gedankenexperiment. Suppose that I'm locked in a\nroom and given a large batch of Chinese writing. \nSuppose furthermore\n(as is indeed the case) that I know no Chinese, either written or\nspoken, and that I'm not \neven confident that I could recognize Chinese\nwriting as Chinese writing distinct from, say, Japanese writing or\nmeaningless squiggles. To me, Chinese writing is just so many\nmeaningless squiggles. \nNow suppose further that after this first batch of Chinese writing I am\ngiven a second batch of Chinese script","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":3,"lines":{"from":1,"to":22}}}}],["a38db9bb-5197-4bd7-a8cb-8a22b7950cae",{"pageContent":"meaningless squiggles. To me, Chinese writing is just so many\nmeaningless squiggles. \nNow suppose further that after this first batch of Chinese writing I am\ngiven a second batch of Chinese script \ntogether with a set of rules for\ncorrelating the second batch with the first batch. The rules are in\nEnglish, and I \nunderstand these rules as well as any other native\nspeaker of English. They enable me to correlate one set of \nformal\nsymbols with another set of formal symbols, and all that 'formal' means\nhere is that I can identify the \nsymbols entirely by their shapes. Now\nsuppose also that I am given a third batch of Chinese symbols together\nwith some instructions, again in English, that enable me to correlate\nelements of this third batch with the first two \nbatches, and these\nrules instruct me how to give back certain Chinese symbols with certain\nsorts of shapes in \nresponse to certain sorts of shapes given me in the\nthird batch. Unknown to me, the people who are giving me \nall of these","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":3,"lines":{"from":22,"to":43}}}}],["999e65ec-a923-45cc-81ad-c9ccf7c285cb",{"pageContent":"sorts of shapes in \nresponse to certain sorts of shapes given me in the\nthird batch. Unknown to me, the people who are giving me \nall of these\nsymbols call the first batch \"a script,\" they call the second batch a\n\"story. ' and they call the third \nbatch \"questions.\" Furthermore, they\ncall the symbols I give them back in response to the third batch\n\"answers \nto the questions.\" and the set of rules in English that they\ngave me, they call \"the program.\"\nNow just to complicate the story a little, imagine that these people\nalso give me stories in English, which I \nunderstand, and they then ask\nme questions in English about these stories, and I give them back\nanswers in \nEnglish. Suppose also that after a while I get so good at\nfollowing the instructions for manipulating the Chinese \nsymbols and\nthe programmers get so good at writing the programs that from the\nexternal point of view that is, \nfrom the point of view of somebody","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":3,"lines":{"from":43,"to":64}}}}],["f945b853-22cd-40bc-a48d-e6af7397bee6",{"pageContent":"symbols and\nthe programmers get so good at writing the programs that from the\nexternal point of view that is, \nfrom the point of view of somebody\noutside the room in which I am locked -- my answers to the questions\nare \nabsolutely indistinguishable from those of native Chinese speakers.\nNobody just looking at my answers can tell \nthat I don't speak a word of\nChinese.\nLet us also suppose that my answers to the English questions are, as\nthey no doubt would be, indistinguishable \nfrom those of other native\nEnglish speakers, for the simple reason that I am a native English\nspeaker. From the \nexternal point of view -- from the point of view of\nsomeone reading my \"answers\" -- the answers to the \nChinese questions and\nthe English questions are equally good. But in the Chinese case, unlike\nthe English case, \nI produce the answers by manipulating uninterpreted\nformal symbols. As far as the Chinese is concerned, I \nsimply behave\nlike a computer; I perform computational operations on formally","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":3,"lines":{"from":64,"to":87}}}}],["e5b9d2e3-af04-4576-ba8f-df7e314b85e6",{"pageContent":"I produce the answers by manipulating uninterpreted\nformal symbols. As far as the Chinese is concerned, I \nsimply behave\nlike a computer; I perform computational operations on formally\nspecified elements. For the \npurposes of the Chinese, I am simply an\ninstantiation of the computer program.\nNow the claims made by strong AI are that the programmed computer\nunderstands the stories and that the \nprogram in some sense explains\nhuman understanding. But we are now in a position to examine these\nclaims in \nlight of our thought experiment.\n1 As regards the first claim, it seems to me quite obvious in the\nexample that I do not understand a word of the \nChinese stories. I have\ninputs and outputs that are indistinguishable from those of the native\nChinese speaker, \nand I can have any formal program you like, but I\nstill understand nothing. For the same reasons, Schank's \ncomputer\nunderstands nothing of any stories. whether in Chinese. English. or\nwhatever. since in the Chinese","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":3,"lines":{"from":87,"to":109}}}}],["bc09bb2f-09f0-4b24-859f-6b1aec74990e",{"pageContent":"still understand nothing. For the same reasons, Schank's \ncomputer\nunderstands nothing of any stories. whether in Chinese. English. or\nwhatever. since in the Chinese \ncase the computer is me. and in cases\nwhere the computer is not me, the computer has nothing more than I \n7/14/03 6:14 PM\nMinds, Brains, and Programs\nPage 3 of 19\nhttp://www.bbsonline.org/documents/a/00/00/04/84/bbs00000484-00/bbs.searle2.html","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":3,"lines":{"from":109,"to":118}}}}],["0c3696c3-1292-45bd-851c-931c93309078",{"pageContent":"have\nin the case where I understand nothing.\n2. As regards the second claim, that the program explains human\nunderstanding, we can see that the computer \nand its program do not\nprovide sufficient conditions of understanding since the computer and\nthe program are \nfunctioning, and there is no understanding. But does it\neven provide a necessary condition or a significant \ncontribution to\nunderstanding? One of the claims made by the supporters of strong AI is\nthat when I understand \na story in English, what I am doing is exactly\nthe same -- or perhaps more of the same -- as what I was doing in\nmanipulating the Chinese symbols. It is simply more formal symbol\nmanipulation that distinguishes the case in \nEnglish, where I do\nunderstand, from the case in Chinese, where I don't. I have not\ndemonstrated that this \nclaim is false, but it would certainly appear an\nincredible claim in the example. Such plausibility as the claim has","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":4,"lines":{"from":1,"to":21}}}}],["b4aac1f3-87c3-439c-92f4-ef191ae85d1a",{"pageContent":"demonstrated that this \nclaim is false, but it would certainly appear an\nincredible claim in the example. Such plausibility as the claim has\nderives from the supposition that we can construct a program that will\nhave the same inputs and outputs as \nnative speakers, and in addition we\nassume that speakers have some level of description where they are also\ninstantiations of a program. \nOn the basis of these two assumptions we assume that even if Schank's\nprogram isn't the whole story about \nunderstanding, it may be part of\nthe story. Well, I suppose that is an empirical possibility, but not\nthe slightest \nreason has so far been given to believe that it is true,\nsince what is suggested though certainly not demonstrated \n-- by the\nexample is that the computer program is simply irrelevant to my\nunderstanding of the story. In the \nChinese case I have everything that\nartificial intelligence can put into me by way of a program, and I\nunderstand","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":4,"lines":{"from":21,"to":41}}}}],["f6aac13d-b5e8-44b2-89b8-b51ec0ac5039",{"pageContent":"understanding of the story. In the \nChinese case I have everything that\nartificial intelligence can put into me by way of a program, and I\nunderstand \nnothing; in the English case I understand everything, and\nthere is so far no reason at all to suppose that my \nunderstanding has\nanything to do with computer programs, that is, with computational\noperations on purely \nformally specified elements. As long as the\nprogram is defined in terms of computational operations on purely\nformally defined elements, what the example suggests is that these by\nthemselves have no interesting connection \nwith understanding. They are\ncertainly not sufficient conditions, and not the slightest reason has\nbeen given to \nsuppose that they are necessary conditions or even that\nthey make a significant contribution to understanding.\nNotice that the force of the argument is not simply that different\nmachines can have the same input and output \nwhile operating on","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":4,"lines":{"from":41,"to":61}}}}],["0c23e0a0-108c-48e6-8255-35d0e18fb9c2",{"pageContent":"they make a significant contribution to understanding.\nNotice that the force of the argument is not simply that different\nmachines can have the same input and output \nwhile operating on\ndifferent formal principles -- that is not the point at all. Rather,\nwhatever purely formal \nprinciples you put into the computer, they will\nnot be sufficient for understanding, since a human will be able to\nfollow the formal principles without understanding anything. No reason\nwhatever has been offered to suppose \nthat such principles are necessary\nor even contributory, since no reason has been given to suppose that\nwhen I \nunderstand English I am operating with any formal program at\nall.\nWell, then, what is it that I have in the case of the English sentences\nthat I do not have in the case of the \nChinese sentences? The obvious\nanswer is that I know what the former mean, while I haven't the\nfaintest idea \nwhat the latter mean. But in what does this consist and","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":4,"lines":{"from":61,"to":81}}}}],["fd84b751-4bc9-433b-b10f-0106af807f7e",{"pageContent":"Chinese sentences? The obvious\nanswer is that I know what the former mean, while I haven't the\nfaintest idea \nwhat the latter mean. But in what does this consist and\nwhy couldn't we give it to a machine, whatever it is? I \nwill return to\nthis question later, but first I want to continue with the example.\nI have had the occasions to present this example to several workers in\nartificial intelligence, and, interestingly, \nthey do not seem to agree\non what the proper reply to it is. I get a surprising variety of\nreplies, and in what \nfollows I will consider the most common of these\n(specified along with their geographic origins).\nBut first I want to block some common misunderstandings about\n\"understanding\": in many of these discussions \none finds a lot of fancy\nfootwork about the word \"understanding.\" My critics point out that\nthere are many \ndifferent degrees of understanding; that \"understanding\"\nis not a simple two-place predicate; that there are even \ndifferent kinds","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":4,"lines":{"from":81,"to":102}}}}],["e2b10f0b-5133-4603-a942-5373ef8b92d2",{"pageContent":"there are many \ndifferent degrees of understanding; that \"understanding\"\nis not a simple two-place predicate; that there are even \ndifferent kinds\nand levels of understanding, and often the law of excluded middle\ndoesn-t even apply in a \nstraightforward way to statements of the form\n\"x understands y; that in many cases it is a matter for decision and\nnot a simple matter of fact whether x understands y; and so on. To all\nof these points I want to say: of course, of \ncourse. But they have\nnothing to do with the points at issue. There are clear cases in which\n\"understanding' \n7/14/03 6:14 PM\nMinds, Brains, and Programs\nPage 4 of 19\nhttp://www.bbsonline.org/documents/a/00/00/04/84/bbs00000484-00/bbs.searle2.html","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":4,"lines":{"from":102,"to":118}}}}],["d8269292-5f3c-409a-b3a5-9844ca8641d0",{"pageContent":"literally applies and clear cases in which it does not\napply; and these two sorts of cases are all I need for this \nargument 2\nI understand stories in English; to a lesser degree I can understand\nstories in French; to a still lesser \ndegree, stories in German; and in\nChinese, not at all. My car and my adding machine, on the other hand,\nunderstand nothing: they are not in that line of business. We often\nattribute \"under standing\" and other cognitive \npredicates by metaphor\nand analogy to cars, adding machines, and other artifacts, but nothing\nis proved by such \nattributions. We say, \"The door knows when to open\nbecause of its photoelectric cell,\" \"The adding machine \nknows how)\n(understands how to, is able) to do addition and subtraction but not\ndivision,\" and \"The thermostat \nperceives chances in the temperature.\"\nThe reason we make these attributions is quite interesting, and it has\nto do with the fact that in artifacts we \nextend our own","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":5,"lines":{"from":1,"to":21}}}}],["53b629b1-1577-40f2-8480-ef696f04983c",{"pageContent":"division,\" and \"The thermostat \nperceives chances in the temperature.\"\nThe reason we make these attributions is quite interesting, and it has\nto do with the fact that in artifacts we \nextend our own\nintentionality;3 our tools are extensions of our purposes, and so we\nfind it natural to make \nmetaphorical attributions of intentionality to\nthem; but I take it no philosophical ice is cut by such examples. The\nsense in which an automatic door \"understands instructions\" from its\nphotoelectric cell is not at all the sense in \nwhich I understand\nEnglish. If the sense in which Schank's programmed computers understand\nstories is \nsupposed to be the metaphorical sense in which the door\nunderstands, and not the sense in which I understand \nEnglish, the issue\nwould not be worth discussing. But Newell and Simon (1963) write that\nthe kind of cognition \nthey claim for computers is exactly the same as\nfor human beings. I like the straightforwardness of this claim, \nand it","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":5,"lines":{"from":21,"to":42}}}}],["d31deca4-bc4d-4962-9c83-b31d5e9f63e6",{"pageContent":"the kind of cognition \nthey claim for computers is exactly the same as\nfor human beings. I like the straightforwardness of this claim, \nand it\nis the sort of claim I will be considering. I will argue that in the\nliteral sense the programmed computer \nunderstands what the car and the\nadding machine understand, namely, exactly nothing. The computer\nunderstanding is not just (like my understanding of German) partial or\nincomplete; it is zero.\nNow to the replies:\nI. The systems reply (Berkeley). \"While it is true that the individual\nperson who is locked in the room does not \nunderstand the story, the\nfact is that he is merely part of a whole system, and the system does\nunderstand the \nstory. The person has a large ledger in front of him in\nwhich are written the rules, he has a lot of scratch paper \nand pencils\nfor doing calculations, he has 'data banks' of sets of Chinese symbols.\nNow, understanding is not \nbeing ascribed to the mere individual; rather","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":5,"lines":{"from":42,"to":63}}}}],["b234fe66-1028-449b-95f8-39e12970bdb0",{"pageContent":"and pencils\nfor doing calculations, he has 'data banks' of sets of Chinese symbols.\nNow, understanding is not \nbeing ascribed to the mere individual; rather\nit is being ascribed to this whole system of which he is a part.\"\nMy response to the systems theory is quite simple: let the individual\ninternalize all of these elements of the \nsystem. He memorizes the rules\nin the ledger and the data banks of Chinese symbols, and he does all\nthe \ncalculations in his head. The individual then incorporates the\nentire system. There isn't anything at all to the \nsystem that he does\nnot encompass. We can even get rid of the room and suppose he works\noutdoors. All the \nsame, he understands nothing of the Chinese, and a\nfortiori neither does the system, because there isn't anything \nin the\nsystem that isn't in him. If he doesn't understand, then there is no\nway the system could understand \nbecause the system is just a part of\nhim.\nActually I feel somewhat embarrassed to give even this answer to the","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":5,"lines":{"from":63,"to":85}}}}],["5a139fe3-75b6-4d9f-b2cd-b330a501be66",{"pageContent":"way the system could understand \nbecause the system is just a part of\nhim.\nActually I feel somewhat embarrassed to give even this answer to the\nsystems theory because the theory seems \nto me so implausible to start\nwith. The idea is that while a person doesn't understand Chinese,\nsomehow the \nconjunction of that person and bits of paper might\nunderstand Chinese. It is not easy for me to imagine how \nsomeone who\nwas not in the grip of an ideology would find the idea at all\nplausible. Still, I think many people \nwho are committed to the ideology\nof strong AI will in the end be inclined to say something very much\nlike this; \nso let us pursue it a bit further. According to one version\nof this view, while the man in the internalized systems \nexample doesn't\nunderstand Chinese in the sense that a native Chinese speaker does\n(because, for example, he \ndoesn't know that the story refers to\nrestaurants and hamburgers, etc.), still \"the man as a formal symbol","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":5,"lines":{"from":85,"to":107}}}}],["bfa99cf3-75d9-4580-a79f-cede4973e359",{"pageContent":"(because, for example, he \ndoesn't know that the story refers to\nrestaurants and hamburgers, etc.), still \"the man as a formal symbol\nmanipulation system\" really does understand Chinese. The subsystem of\nthe man that is the formal symbol \nmanipulation system for Chinese\nshould not be confused with the subsystem for English.\nSo there are really two subsystems in the man; one understands English,\nthe other Chinese, and \"it's just that the \n7/14/03 6:14 PM\nMinds, Brains, and Programs\nPage 5 of 19\nhttp://www.bbsonline.org/documents/a/00/00/04/84/bbs00000484-00/bbs.searle2.html","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":5,"lines":{"from":107,"to":119}}}}],["83391a0f-ade0-484e-92ca-7087743b8b25",{"pageContent":"two systems have little to\ndo with each other.\" But, I want to reply, not only do they have little\nto do with each \nother, they are not even remotely alike. The subsystem\nthat understands English (assuming we allow ourselves \nto talk in this\njargon of \"subsystems\" for a moment) knows that the stories are about\nrestaurants and eating \nhamburgers, he knows that he is being asked\nquestions about restaurants and that he is answering questions as \nbest\nhe can by making various inferences from the content of the story, and\nso on. But the Chinese system \nknows none of this. Whereas the English\nsubsystem knows that \"hamburgers\" refers to hamburgers, the Chinese\nsubsystem knows only that \"squiggle squiggle\" is followed by \"squoggle\nsquoggle.\" All he knows is that various \nformal symbols are being\nintroduced at one end and manipulated according to rules written in\nEnglish, and other \nsymbols are going out at the other end. \nThe whole point of the original example was to argue that such symbol","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":6,"lines":{"from":1,"to":22}}}}],["ee528bdd-199b-4472-8285-57ee046d3733",{"pageContent":"introduced at one end and manipulated according to rules written in\nEnglish, and other \nsymbols are going out at the other end. \nThe whole point of the original example was to argue that such symbol\nmanipulation by itself couldn't be \nsufficient for understanding Chinese\nin any literal sense because the man could write \"squoggle squoggle\"\nafter \n\"squiggle squiggle\" without understanding anything in Chinese.\nAnd it doesn't meet that argument to postulate \nsubsystems within the\nman, because the subsystems are no better off than the man was in the\nfirst place; they \nstill don't have anything even remotely like what the\nEnglish-speaking man (or subsystem) has. Indeed, in the \ncase as\ndescribed, the Chinese subsystem is simply a part of the English\nsubsystem, a part that engages in \nmeaningless symbol manipulation\naccording to rules in English.\nLet us ask ourselves what is supposed to motivate the systems reply in\nthe first place; that is, what independent \ngrounds are there supposed","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":6,"lines":{"from":22,"to":44}}}}],["67ff5dc5-efb1-4b35-9cb7-f0cab6738b0c",{"pageContent":"according to rules in English.\nLet us ask ourselves what is supposed to motivate the systems reply in\nthe first place; that is, what independent \ngrounds are there supposed\nto be for saying that the agent must have a subsystem within him that\nliterally \nunderstands stories in Chinese? As far as I can tell the only\ngrounds are that in the example I have the same \ninput and output as\nnative Chinese speakers and a program that goes from one to the other.\nBut the whole \npoint of the examples has been to try to show that that\ncouldn't be sufficient for understanding, in the sense in \nwhich I\nunderstand stories in English, because a person, and hence the set of\nsystems that go to make up a \nperson, could have the right combination\nof input, output, and program and still not understand anything in the\nrelevant literal sense in which I understand English. \nThe only motivation for saying there must be a subsystem in me that\nunderstands Chinese is that I have a","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":6,"lines":{"from":44,"to":64}}}}],["cf35ae71-771b-4952-90ac-109ab1c5f6ea",{"pageContent":"relevant literal sense in which I understand English. \nThe only motivation for saying there must be a subsystem in me that\nunderstands Chinese is that I have a \nprogram and I can pass the Turing\ntest; I can fool native Chinese speakers. But precisely one of the\npoints at \nissue is the adequacy of the Turing test. The example shows\nthat there could be two \"systems,\" both of which \npass the Turing test,\nbut only one of which understands; and it is no argument against this\npoint to say that since \nthey both pass the Turing test they must both\nunderstand, since this claim fails to meet the argument that the \nsystem\nin me that understands English has a great deal more than the system\nthat merely processes Chinese. In \nshort, the systems reply simply begs\nthe question by insisting without argument that the system must\nunderstand \nChinese.\nFurthermore, the systems reply would appear to lead to consequences\nthat are independently absurd. If we are \nto conclude that there must be","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":6,"lines":{"from":64,"to":86}}}}],["b3763238-769a-46cb-9c9f-8b996cb8b066",{"pageContent":"understand \nChinese.\nFurthermore, the systems reply would appear to lead to consequences\nthat are independently absurd. If we are \nto conclude that there must be\ncognition in me on the grounds that I have a certain sort of input and\noutput and a \nprogram in between, then it looks like all sorts of\nnoncognitive subsystems are going to turn out to be cognitive. \nFor\nexample, there is a level of description at which my stomach does\ninformation processing, and it instantiates \nany number of computer\nprograms, but I take it we do not want to say that it has any\nunderstanding [cf. \nPylyshyn: \"Computation and Cognition\" BBS 3(1)\n1980]. But if we accept the systems reply, then it is hard to \nsee how\nwe avoid saying that stomach, heart, liver, and so on, are all\nunderstanding subsystems, since there is \nno principled way to\ndistinguish the motivation for saying the Chinese subsystem understands\nfrom saying that \nthe stomach understands. It is, by the way, not an","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":6,"lines":{"from":86,"to":109}}}}],["f4057c73-a4f2-4623-9359-6928f550f6d9",{"pageContent":"no principled way to\ndistinguish the motivation for saying the Chinese subsystem understands\nfrom saying that \nthe stomach understands. It is, by the way, not an\nanswer to this point to say that the Chinese system has \ninformation as\ninput and output and the stomach has food and food products as input\nand output, since from the \npoint of view of the agent, from my point of\nview, there is no information in either the food or the Chinese -- the\nChinese is just so many meaningless squiggles. The information in the\nChinese case is solely in the eyes of the \nprogrammers and the\ninterpreters, and there is nothing to prevent them from treating the\ninput and output of my \ndigestive organs as information if they so\ndesire.\n7/14/03 6:14 PM\nMinds, Brains, and Programs\nPage 6 of 19\nhttp://www.bbsonline.org/documents/a/00/00/04/84/bbs00000484-00/bbs.searle2.html","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":6,"lines":{"from":109,"to":129}}}}],["6a7b6fa8-ba5d-4cdc-804c-adfcddd856e8",{"pageContent":"This last point bears on some independent problems in strong AI, and it\nis worth digressing for a moment to \nexplain it. If strong AI is to be a\nbranch of psychology, then it must be able to distinguish those systems\nthat are \ngenuinely mental from those that are not. It must be able to\ndistinguish the principles on which the mind works \nfrom those on which\nnonmental systems work; otherwise it will offer us no explanations of\nwhat is specifically \nmental about the mental. And the mental-nonmental\ndistinction cannot be just in the eye of the beholder but it \nmust be\nintrinsic to the systems; otherwise it would be up to any beholder to\ntreat people as nonmental and, for \nexample, hurricanes as mental if he\nlikes. But quite often in the AI literature the distinction is blurred\nin ways \nthat would in the long run prove disastrous to the claim that\nAI is a cognitive inquiry. McCarthy, for example, \nwrites, '-Machines as\nsimple as thermostats can be said to have beliefs, and having beliefs","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":7,"lines":{"from":1,"to":22}}}}],["3ff8a562-ad77-471d-ade5-d01f06941343",{"pageContent":"AI is a cognitive inquiry. McCarthy, for example, \nwrites, '-Machines as\nsimple as thermostats can be said to have beliefs, and having beliefs\nseems to be a \ncharacteristic of most machines capable of problem\nsolving performance\" (McCarthy 1979). \nAnyone who thinks strong AI has a chance as a theory of the mind ought\nto ponder the implications of that \nremark. We are asked to accept it as\na discovery of strong AI that the hunk of metal on the wall that we use\nto \nregulate the temperature has beliefs in exactly the same sense that\nwe, our spouses, and our children have \nbeliefs, and furthermore that\n\"most\" of the other machines in the room -- telephone, tape recorder,\nadding \nmachine, electric light switch, -- also have beliefs in this\nliteral sense. It is not the aim of this article to argue \nagainst\nMcCarthy's point, so I will simply assert the following without\nargument. The study of the mind starts \nwith such facts as that humans","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":7,"lines":{"from":22,"to":43}}}}],["2a5d9417-726a-4bae-a9a1-171181232b9e",{"pageContent":"against\nMcCarthy's point, so I will simply assert the following without\nargument. The study of the mind starts \nwith such facts as that humans\nhave beliefs, while thermostats, telephones, and adding machines don't.\nIf you get \na theory that denies this point you have produced a\ncounterexample to the theory and the theory is false. \nOne gets the impression that people in AI who write this sort of thing\nthink they can get away with it because \nthey don't really take it\nseriously, and they don't think anyone else will either. I propose for\na moment at least, to \ntake it seriously. Think hard for one minute\nabout what would be necessary to establish that that hunk of metal \non\nthe wall over there had real beliefs beliefs with direction of fit,\npropositional content, and conditions of \nsatisfaction; beliefs that had\nthe possibility of being strong beliefs or weak beliefs; nervous,\nanxious, or secure \nbeliefs; dogmatic, rational, or superstitious","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":7,"lines":{"from":43,"to":64}}}}],["ab507bc0-920b-42b1-97db-211960da201d",{"pageContent":"satisfaction; beliefs that had\nthe possibility of being strong beliefs or weak beliefs; nervous,\nanxious, or secure \nbeliefs; dogmatic, rational, or superstitious\nbeliefs; blind faiths or hesitant cogitations; any kind of beliefs. The\nthermostat is not a candidate. Neither is stomach, liver adding\nmachine, or telephone. However, since we are \ntaking the idea seriously,\nnotice that its truth would be fatal to strong AI's claim to be a\nscience of the mind. For \nnow the mind is everywhere. What we wanted to\nknow is what distinguishes the mind from thermostats and \nlivers. And if\nMcCarthy were right, strong AI wouldn't have a hope of telling us\nthat.\nII. The Robot Reply (Yale). \"Suppose we wrote a different kind of\nprogram from Schank's program. Suppose \nwe put a computer inside a\nrobot, and this computer would not just take in formal symbols as input\nand give out \nformal symbols as output, but rather would actually\noperate the robot in such a way that the robot does \nsomething very much","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":7,"lines":{"from":64,"to":86}}}}],["b40b37d2-46ab-4c50-95b4-432534f563a5",{"pageContent":"and give out \nformal symbols as output, but rather would actually\noperate the robot in such a way that the robot does \nsomething very much\nlike perceiving, walking, moving about, hammering nails, eating\ndrinking -- anything you \nlike. The robot would, for example have a\ntelevision camera attached to it that enabled it to 'see,' it would\nhave \narms and legs that enabled it to 'act,' and all of this would be\ncontrolled by its computer 'brain.' Such a robot \nwould, unlike Schank's\ncomputer, have genuine understanding and other mental states.\"\nThe first thing to notice about the robot reply is that it tacitly\nconcedes that cognition is not solely a matter of \nformal symbol\nmanipulation, since this reply adds a set of causal relation with the\noutside world [cf. Fodor: \n\"Methodological Solipsism\" BBS 3(1) 1980].\nBut the answer to the robot reply is that the addition of such\n\"perceptual\" and \"motor\" capacities adds nothing by way of\nunderstanding, in particular, or intentionality, in","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":7,"lines":{"from":86,"to":107}}}}],["92f16137-05e3-4001-b5d6-2f29a20088ca",{"pageContent":"But the answer to the robot reply is that the addition of such\n\"perceptual\" and \"motor\" capacities adds nothing by way of\nunderstanding, in particular, or intentionality, in \ngeneral, to\nSchank's original program. To see this, notice that the same thought\nexperiment applies to the robot \ncase. Suppose that instead of the\ncomputer inside the robot, you put me inside the room and, as in the\noriginal \nChinese case, you give me more Chinese symbols with more\ninstructions in English for matching Chinese \nsymbols to Chinese symbols\nand feeding back Chinese symbols to the outside. Suppose, unknown to\nme, some \nof the Chinese symbols that come to me come from a television\ncamera attached to the robot and other \n7/14/03 6:14 PM\nMinds, Brains, and Programs\nPage 7 of 19\nhttp://www.bbsonline.org/documents/a/00/00/04/84/bbs00000484-00/bbs.searle2.html","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":7,"lines":{"from":107,"to":126}}}}],["b42cb937-67f1-4bad-808b-6977dc754761",{"pageContent":"Chinese symbols that I am giving\nout serve to make the motors inside the robot move the robot's legs or\narms. \nIt is important to emphasize that all I am doing is manipulating\nformal symbols: I know none of these other facts. \nI am receiving\n\"information\" from the robot's \"perceptual\" apparatus, and I am giving\nout \"instructions\" to its \nmotor apparatus without knowing either of\nthese facts. I am the robot's homunculus, but unlike the traditional\nhomunculus, I don't know what's going on. I don't understand anything\nexcept the rules for symbol \nmanipulation. Now in this case I want to\nsay that the robot has no intentional states at all; it is simply\nmoving \nabout as a result of its electrical wiring and its program. And\nfurthermore, by instantiating the program I have no \nintentional states\nof the relevant type. All I do is follow formal instructions about\nmanipulating formal symbols.\nIII. The brain simulator reply (Berkeley and M.I.T.). \"Suppose we","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":8,"lines":{"from":1,"to":21}}}}],["2b086743-2906-4f42-9086-840b3ec74e6e",{"pageContent":"intentional states\nof the relevant type. All I do is follow formal instructions about\nmanipulating formal symbols.\nIII. The brain simulator reply (Berkeley and M.I.T.). \"Suppose we\ndesign a program that doesn't represent \ninformation that we have about\nthe world, such as the information in Schank's scripts, but simulates\nthe actual \nsequence of neuron firings at the synapses of the brain of a\nnative Chinese speaker when he understands stories \nin Chinese and gives\nanswers to them. The machine takes in Chinese stories and\nquestions about them as input, \nit simulates the formal l structure of\nactual Chinese brains in processing these stories, and it gives out\nChinese \nanswers as outputs. We can even imagine that the machine\noperates, not with a single serial program, but with a \nwhole set of\nprograms operating in parallel, in the manner that actual human brains\npresumably operate when \nthey process natural language. Now surely in","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":8,"lines":{"from":21,"to":42}}}}],["19f85a5f-d964-4b1d-ba86-d09683ec5256",{"pageContent":"whole set of\nprograms operating in parallel, in the manner that actual human brains\npresumably operate when \nthey process natural language. Now surely in\nsuch a case we would have to say that the machine understood \nthe\nstories; and if we refuse to say that, wouldn't we also have to deny\nthat native Chinese speakers understood \nthe stories? At the level of\nthe synapses, what would or could be different about the program of the\ncomputer \nand the program of the Chinese brain?\"\nBefore countering this reply I want to digress to note that it is an\nodd reply for any partisan of artificial \nintelligence (or\nfunctionalism, etc.) to make: I thought the whole idea of\nstrong AI is that we don't need to know \nhow the brain works to know how\nthe mind works. The basic hypothesis, or so I had supposed, was that\nthere \nis a level of mental operations consisting of computational\nprocesses over formal elements that constitute the \nessence of the","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":8,"lines":{"from":42,"to":64}}}}],["933760d9-52a1-4dd6-b52a-6eeaad31dfe2",{"pageContent":"there \nis a level of mental operations consisting of computational\nprocesses over formal elements that constitute the \nessence of the\nmental and can be realized in all sorts of different brain processes,\nin the same way that any \ncomputer program can be realized in different\ncomputer hardwares: on the assumptions of strong AI, the mind \nis to the\nbrain as the program is to the hardware, and thus we can understand the\nmind without doing \nneurophysiology. If we had to know how the brain\nworked to do AI, we wouldn't bother with AI. However, \neven getting this\nclose to the operation of the brain is still not sufficient to produce\nunderstanding. To see this, \nimagine that instead of a mono lingual man\nin a room shuffling symbols we have the man operate an elaborate \nset of\nwater pipes with valves connecting them. When the man receives the\nChinese symbols, he looks up in the \nprogram, written in English, which\nvalves he has to turn on and off. Each water connection corresponds to\na","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":8,"lines":{"from":64,"to":87}}}}],["dd1d3295-7f7f-40e8-87a7-282b012ff64a",{"pageContent":"Chinese symbols, he looks up in the \nprogram, written in English, which\nvalves he has to turn on and off. Each water connection corresponds to\na \nsynapse in the Chinese brain, and the whole system is rigged up so\nthat after doing all the right firings, that is \nafter turning on all\nthe right faucets, the Chinese answers pop out at the output end of the\nseries of pipes.\nI Now where is the understanding in this system? It takes Chinese as\ninput, it simulates the formal structure of \nthe synapses of the Chinese\nbrain, and it gives Chinese as output. But the man certainly doesn-t\nunderstand \nChinese, and neither do the water pipes, and if we are\ntempted to adopt what I think is the absurd view that \nsomehow the\nconjunction of man and water pipes understands, remember that in\nprinciple the man can \ninternalize the formal structure of the water\npipes and do all the \"neuron firings\" in his imagination. The problem\nwith the brain simulator is that it is simulating the wrong things","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":8,"lines":{"from":87,"to":108}}}}],["17e26113-2e89-4317-85b6-5bbe420e041f",{"pageContent":"internalize the formal structure of the water\npipes and do all the \"neuron firings\" in his imagination. The problem\nwith the brain simulator is that it is simulating the wrong things\nabout the brain. As long as it simulates only the \nformal structure of\nthe sequence of neuron firings at the synapses, it won't have simulated\nwhat matters about \nthe brain, namely its causal properties, its ability\nto produce intentional states. And that the formal properties are \nnot\nsufficient for the causal properties is shown by the water pipe\nexample: we can have all the formal \nproperties carved off from the\nrelevant neurobiological causal properties.\nIV. The combination reply (Berkeley and Stanford). 'While each of the\nprevious three replies might not be \ncompletely convincing by itself as\na refutation of the Chinese room counterexample, if you take all three\ntogether \n7/14/03 6:14 PM\nMinds, Brains, and Programs\nPage 8 of 19","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":8,"lines":{"from":108,"to":129}}}}],["668d8b75-d791-4413-8847-9e5a05676deb",{"pageContent":"completely convincing by itself as\na refutation of the Chinese room counterexample, if you take all three\ntogether \n7/14/03 6:14 PM\nMinds, Brains, and Programs\nPage 8 of 19\nhttp://www.bbsonline.org/documents/a/00/00/04/84/bbs00000484-00/bbs.searle2.html","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":8,"lines":{"from":129,"to":135}}}}],["90ebfa2f-b474-40c4-b21f-c4a17350dffe",{"pageContent":"they are collectively much more convincing and even decisive.\nImagine a robot with a brain-shaped computer \nlodged in its cranial\ncavity, imagine the computer programmed with all the synapses of a\nhuman brain, imagine \nthe whole behavior of the robot is\nindistinguishable from human behavior, and now think of the whole thing\nas a \nunified system and not just as a computer with inputs and outputs.\nSurely in such a case we would have to \nascribe intentionality to the\nsystem. '\nI entirely agree that in such a case we would find it rational and\nindeed irresistible to accept the hypothesis that \nthe robot had\nintentionality, as long as we knew nothing more about it. Indeed,\nbesides appearance and \nbehavior, the other elements of the combination\nare really irrelevant. If we could build a robot whose behavior \nwas\nindistinguishable over a large range from human behavior, we would\nattribute intentionality to it, pending \nsome reason not to. We wouldn't","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":9,"lines":{"from":1,"to":23}}}}],["55fa8823-a923-428c-b796-93324e6dce87",{"pageContent":"was\nindistinguishable over a large range from human behavior, we would\nattribute intentionality to it, pending \nsome reason not to. We wouldn't\nneed to know in advance that its computer brain was a formal analogue\nof the \nhuman brain.\nBut I really don't see that this is any help to the claims of strong\nAI; and here-s why: According to strong AI, \ninstantiating a formal\nprogram with the right input and output is a sufficient condition of,\nindeed is constitutive of, \nintentionality. As Newell (1979) puts it,\nthe essence of the mental is the operation of a physical symbol system.\nBut the attributions of intentionality that we make to the robot in\nthis example have nothing to do with formal \nprograms. They are simply\nbased on the assumption that if the robot looks and behaves\nsufficiently like us, then \nwe would suppose, until proven otherwise,\nthat it must have mental states like ours that cause and are \nexpressed\nby its behavior and it must have an inner mechanism capable of","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":9,"lines":{"from":23,"to":45}}}}],["a290985a-58b2-4688-aa41-3eebdee65342",{"pageContent":"we would suppose, until proven otherwise,\nthat it must have mental states like ours that cause and are \nexpressed\nby its behavior and it must have an inner mechanism capable of\nproducing such mental states. If we \nknew independently how to account\nfor its behavior without such assumptions we would not attribute\nintentionality to it especially if we knew it had a formal program. And\nthis is precisely the point of my earlier \nreply to objection 11.\nSuppose we knew that the robot's behavior was entirely accounted for by\nthe fact that a man inside it was \nreceiving uninterpreted formal\nsymbols from the robot's sensory receptors and sending out\nuninterpreted formal \nsymbols to its motor mechanisms, and the man was\ndoing this symbol manipulation in accordance with a bunch \nof rules.\nFurthermore, suppose the man knows none of these facts about the robot,\nall he knows is which \noperations to perform on which meaningless\nsymbols. In such a case we would regard the robot as an ingenious","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":9,"lines":{"from":45,"to":66}}}}],["8d92b6e0-d61c-4876-b375-d90424913d2c",{"pageContent":"all he knows is which \noperations to perform on which meaningless\nsymbols. In such a case we would regard the robot as an ingenious\nmechanical dummy. The hypothesis that the dummy has a mind would now\nbe unwarranted and unnecessary, \nfor there is now no longer any reason\nto ascribe intentionality to the robot or to the system of which it is\na part \n(except of course for the man's intentionality in manipulating\nthe symbols). The formal symbol manipulations go \non, the input and\noutput are correctly matched, but the only real locus of intentionality\nis the man, and he doesn't \nknow any of the relevant intentional states;\nhe doesn't, for example, see what comes into the robot's eyes, he\ndoesn't intend to move the robot's arm, and he doesn't understand any\nof the remarks made to or by the robot. \nNor, for the reasons stated\nearlier, does the system of which man and robot are a part.\nTo see this point, contrast this case with cases in which we find it","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":9,"lines":{"from":66,"to":85}}}}],["bc6e19d1-568f-46b6-9c0f-e3d077b06fb6",{"pageContent":"of the remarks made to or by the robot. \nNor, for the reasons stated\nearlier, does the system of which man and robot are a part.\nTo see this point, contrast this case with cases in which we find it\ncompletely natural to ascribe intentionality to \nmembers of certain\nother primate species such as apes and monkeys and to domestic animals\nsuch as dogs. The \nreasons we find it natural are, roughly, two: we\ncan't make sense of the animal's behavior without the ascription \nof\nintentionality and we can see that the beasts are made of similar stuff\nto ourselves -- that is an eye, that a \nnose, this is its skin, and so\non. Given the coherence of the animal's behavior and the assumption of\nthe same \ncausal stuff underlying it, we assume both that the animal\nmust have mental states underlying its behavior, and \nthat the mental\nstates must be produced by mechanisms made out of the stuff that is\nlike our stuff. We would \ncertainly make similar assumptions about the","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":9,"lines":{"from":85,"to":106}}}}],["d2564fd8-0d14-4b35-aa51-69bf0d0b20ab",{"pageContent":"that the mental\nstates must be produced by mechanisms made out of the stuff that is\nlike our stuff. We would \ncertainly make similar assumptions about the\nrobot unless we had some reason not to, but as soon as we knew \nthat the\nbehavior was the result of a formal program, and that the actual causal\nproperties of the physical \nsubstance were irrelevant we would abandon\nthe assumption of intentionality. [See \"Cognition and \nConsciousness in\nNonhuman Species BBS 1(4) 1978.]\n7/14/03 6:14 PM\nMinds, Brains, and Programs\nPage 9 of 19\nhttp://www.bbsonline.org/documents/a/00/00/04/84/bbs00000484-00/bbs.searle2.html","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":9,"lines":{"from":106,"to":121}}}}],["ffe6f862-a82a-4481-a144-e8fd39f78f66",{"pageContent":"There are two other responses to my example that come up frequently\n(and so are worth discussing) but really \nmiss the point.\nV. The other minds reply (Yale). \"How do you know that other people\nunderstand Chinese or anything else? \nOnly by their behavior. Now the\ncomputer can pass the behavioral tests as well as they can (in\nprinciple), so if \nyou are going to attribute cognition to other people\nyou must in principle also attribute it to computers. '\nThis objection really is only worth a short reply. The problem in this\ndiscussion is not about how I know that \nother people have cognitive\nstates, but rather what it is that I am attributing to them when I\nattribute cognitive \nstates to them. The thrust of the argument is that\nit couldn't be just computational processes and their output \nbecause\nthe computational processes and their output can exist without the\ncognitive state. It is no answer to \nthis argument to feign anesthesia.","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":10,"lines":{"from":1,"to":21}}}}],["75ae13a1-300d-422f-8b6a-d0f1df930a4e",{"pageContent":"because\nthe computational processes and their output can exist without the\ncognitive state. It is no answer to \nthis argument to feign anesthesia.\nIn 'cognitive sciences\" one presupposes the reality and knowability of\nthe \nmental in the same way that in physical sciences one has to\npresuppose the reality and knowability of physical \nobjects.\nVI. The many mansions reply (Berkeley). \"Your whole argument\npresupposes that AI is only about analogue \nand digital computers. But\nthat just happens to be the present state of technology. Whatever these\ncausal \nprocesses are that you say are essential for intentionality\n(assuming you are right), eventually we will be able to \nbuild devices\nthat have these causal processes, and that will be artificial\nintelligence. So your arguments are in \nno way directed at the ability\nof artificial intelligence to produce and explain cognition.\"\nI really have no objection to this reply save to say that it in effect\ntrivializes the project of strong AI by","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":10,"lines":{"from":21,"to":43}}}}],["a9ea1661-76ee-4f57-a41a-5cdbbe655f18",{"pageContent":"of artificial intelligence to produce and explain cognition.\"\nI really have no objection to this reply save to say that it in effect\ntrivializes the project of strong AI by \nredefining it as whatever\nartificially produces and explains cognition. The interest of the\noriginal claim made on \nbehalf of artificial intelligence is that it was\na precise, well defined thesis: mental processes are computational\nprocesses over formally defined elements. I have been concerned to\nchallenge that thesis. If the claim is \nredefined so that it is no\nlonger that thesis, my objections no longer apply because there is no\nlonger a testable \nhypothesis for them to apply to.\nLet us now return to the question I promised I would try to answer:\ngranted that in my original example I \nunderstand the English and I do\nnot understand the Chinese, and granted therefore that the machine\ndoesn't \nunderstand either English or Chinese, still there must be\nsomething about me that makes it the case that I","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":10,"lines":{"from":43,"to":63}}}}],["705ee9ed-edba-432d-9a38-a50e9e36ba10",{"pageContent":"not understand the Chinese, and granted therefore that the machine\ndoesn't \nunderstand either English or Chinese, still there must be\nsomething about me that makes it the case that I \nunderstand English and\na corresponding something lacking in me that makes it the case that I\nfail to understand \nChinese. Now why couldn't we give those somethings,\nwhatever they are, to a machine?\nI see no reason in principle why we couldn't give a machine the\ncapacity to understand English or Chinese, \nsince in an important sense\nour bodies with our brains are precisely such machines. But I do see\nvery strong \narguments for saying that we could not give such a thing to\na machine where the operation of the machine is \ndefined solely in terms\nof computational processes over formally defined elements; that is,\nwhere the operation \nof the machine is defined as an instantiation of a\ncomputer program. It is not because I am the instantiation of a","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":10,"lines":{"from":63,"to":83}}}}],["af7df7cb-c8f6-4bf9-8663-c035a4478298",{"pageContent":"where the operation \nof the machine is defined as an instantiation of a\ncomputer program. It is not because I am the instantiation of a\ncomputer program that I am able to understand English and have other\nforms of intentionality (I am, I suppose, \nthe instantiation of any\nnumber of computer programs), but as far as we know it is because I am\na certain sort \nof organism with a certain biological (i.e. chemical and\nphysical) structure, and this structure, under certain \nconditions, is\ncausally capable of producing perception, action, understanding,\nlearning, and other intentional \nphenomena. And part of the point of the\npresent argument is that only something that had those causal powers\ncould have that intentionality. Perhaps other physical and chemical\nprocesses could produce exactly these \neffects; perhaps, for example,\nMartians also have intentionality but their brains are made of\ndifferent stuff. That \nis an empirical question, rather like the","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":10,"lines":{"from":83,"to":103}}}}],["39763ac5-0c50-44ea-a93d-b60194e755e8",{"pageContent":"processes could produce exactly these \neffects; perhaps, for example,\nMartians also have intentionality but their brains are made of\ndifferent stuff. That \nis an empirical question, rather like the\nquestion whether photosynthesis can be done by something with a\nchemistry different from that of chlorophyll.\n7/14/03 6:14 PM\nMinds, Brains, and Programs\nPage 10 of 19\nhttp://www.bbsonline.org/documents/a/00/00/04/84/bbs00000484-00/bbs.searle2.html","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":10,"lines":{"from":103,"to":113}}}}],["82cfefa5-64de-42f9-a933-b0be7eb5726e",{"pageContent":"But the main point of the present argument is that no purely formal\nmodel will ever be sufficient by itself for \nintentionality because the\nformal properties are not by themselves constitutive of intentionality,\nand they have by \nthemselves no causal powers except the power, when\ninstantiated, to produce the next stage of the formalism \nwhen the\nmachine is running. And any other causal properties that particular\nrealizations of the formal model \nhave, are irrelevant to the formal\nmodel because we can always put the same formal model in a different\nrealization where those causal properties are obviously absent. Even\nif, by some miracle Chinese speakers \nexactly realize Schank's program,\nwe can put the same program in English speakers, water pipes, or\ncomputers, none of which understand Chinese, the program\nnotwithstanding.\nWhat matters about brain operations is not the formal shadow cast by\nthe sequence of synapses but rather the \nactual properties of the","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":11,"lines":{"from":1,"to":21}}}}],["1e4e7096-a22c-43fc-8fae-89b1bc313276",{"pageContent":"notwithstanding.\nWhat matters about brain operations is not the formal shadow cast by\nthe sequence of synapses but rather the \nactual properties of the\nsequences. All the arguments for the strong version of artificial\nintelligence that I have \nseen insist on drawing an outline around the\nshadows cast by cognition and then claiming that the shadows are \nthe\nreal thing. By way of concluding I want to try to state some of the\ngeneral philosophical points implicit in the \nargument. For clarity I\nwill try to do it in a question and answer fashion, and I begin with\nthat old chestnut of a \nquestion:\n\"Could a machine think?\"\nThe answer is, obviously, yes. We are precisely such machines.\n\"Yes, but could an artifact, a man-made machine think?\"\nAssuming it is possible to produce artificially a machine with a\nnervous system, neurons with axons and \ndendrites, and all the rest of\nit, sufficiently like ours, again the answer to the question seems to\nbe obviously, yes.","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":11,"lines":{"from":21,"to":43}}}}],["fd83b3da-74fe-4acd-b30a-0b6a5ca1d45b",{"pageContent":"nervous system, neurons with axons and \ndendrites, and all the rest of\nit, sufficiently like ours, again the answer to the question seems to\nbe obviously, yes. \nIf you can exactly duplicate the causes, you could\nduplicate the effects. And indeed it might be possible to \nproduce\nconsciousness, intentionality, and all the rest of it using some other\nsorts of chemical principles than \nthose that human beings use. It is,\nas I said, an empirical question. \"OK, but could a digital computer\nthink?\"\nIf by \"digital computer\" we mean anything at all that has a level of\ndescription where it can correctly be \ndescribed as the instantiation of\na computer program, then again the answer is, of course, yes, since we\nare the \ninstantiations of any number of computer programs, and we can\nthink.\n\"But could something think, understand, and so on solely in virtue of\nbeing a computer with the right sort of \nprogram? Could instantiating a\nprogram, the right program of course, by itself be a sufficient","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":11,"lines":{"from":43,"to":65}}}}],["9c6f8db5-24d0-46d6-9806-073a6753fe8b",{"pageContent":"being a computer with the right sort of \nprogram? Could instantiating a\nprogram, the right program of course, by itself be a sufficient\ncondition of \nunderstanding?\"\nThis I think is the right question to ask, though it is usually\nconfused with one or more of the earlier questions, \nand the answer to\nit is no.\n\"Why not?\"\nBecause the formal symbol manipulations by themselves don't have any\nintentionality; they are quite \nmeaningless; they aren't even symbol\nmanipulations, since the symbols don't symbolize anything. In the\nlinguistic \njargon, they have only a syntax but no semantics. Such\nintentionality as computers appear to have is solely in \nthe minds of\nthose who program them and those who use them, those who send in the\ninput and those who \ninterpret the output.\nThe aim of the Chinese room example was to try to show this by showing\nthat as soon as we put something \n7/14/03 6:14 PM\nMinds, Brains, and Programs\nPage 11 of 19","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":11,"lines":{"from":65,"to":90}}}}],["338812a7-54cb-45fb-a6e0-7c93d24fba50",{"pageContent":"interpret the output.\nThe aim of the Chinese room example was to try to show this by showing\nthat as soon as we put something \n7/14/03 6:14 PM\nMinds, Brains, and Programs\nPage 11 of 19\nhttp://www.bbsonline.org/documents/a/00/00/04/84/bbs00000484-00/bbs.searle2.html","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":11,"lines":{"from":90,"to":96}}}}],["97cc6803-0d4a-432a-ae9d-89b38c115b7d",{"pageContent":"into the system that really does have\nintentionality (a man), and we program him with the formal program, you\ncan see that the formal program carries no additional intentionality.\nIt adds nothing, for example, to a man's \nability to understand\nChinese.\nPrecisely that feature of AI that seemed so appealing -- the distinction\nbetween the program and the realization \n-- proves fatal to the claim\nthat simulation could be duplication. The distinction between the\nprogram and its \nrealization in the hardware seems to be parallel to the\ndistinction between the level of mental operations and the \nlevel of\nbrain operations. And if we could describe the level of mental\noperations as a formal program, then it \nseems we could describe what\nwas essential about the mind without doing either introspective\npsychology or \nneurophysiology of the brain. But the equation, \"mind is\nto brain as program is to hardware\" breaks down at \nseveral points\namong them the following three:","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":12,"lines":{"from":1,"to":23}}}}],["35c87cc9-cab7-4646-a3f0-58222bd15274",{"pageContent":"psychology or \nneurophysiology of the brain. But the equation, \"mind is\nto brain as program is to hardware\" breaks down at \nseveral points\namong them the following three:\nFirst, the distinction between program and realization has the\nconsequence that the same program could have \nall sorts of crazy\nrealizations that had no form of intentionality. Weizenbaum (1976, Ch.\n2), for example, shows \nin detail how to construct a computer using a\nroll of toilet paper and a pile of small stones. Similarly, the Chinese\nstory understanding program can be programmed into a sequence of water\npipes, a set of wind machines, or a \nmonolingual English speaker, none\nof which thereby acquires an understanding of Chinese. Stones, toilet\npaper, \nwind, and water pipes are the wrong kind of stuff to have\nintentionality in the first place -- only something that \nhas the same\ncausal powers as brains can have intentionality -- and though the\nEnglish speaker has the right \nkind of stuff for intentionality you can","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":12,"lines":{"from":23,"to":45}}}}],["4a451990-a1de-4a51-8076-9976a64a2ca8",{"pageContent":"has the same\ncausal powers as brains can have intentionality -- and though the\nEnglish speaker has the right \nkind of stuff for intentionality you can\neasily see that he doesn't get any extra intentionality by memorizing\nthe \nprogram, since memorizing it won't teach him Chinese.\nSecond, the program is purely formal, but the intentional states are\nnot in that way formal. They are defined in \nterms of their content, not\ntheir form. The belief that it is raining, for example, is not defined\nas a certain formal \nshape, but as a certain mental content with\nconditions of satisfaction, a direction of fit (see Searle 1979), and\nthe \nlike. Indeed the belief as such hasn't even got a formal shape in\nthis syntactic sense, since one and the same \nbelief can be given an\nindefinite number of different syntactic expressions in different\nlinguistic systems.\nThird, as I mentioned before, mental states and events are literally a\nproduct of the operation of the brain, but \nthe program is not in that","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":12,"lines":{"from":45,"to":67}}}}],["95e0109e-c922-435c-a96b-59e96f2f61a1",{"pageContent":"linguistic systems.\nThird, as I mentioned before, mental states and events are literally a\nproduct of the operation of the brain, but \nthe program is not in that\nway a product of the computer.\n-Well if programs are in no way constitutive of mental processes, why\nhave so many people believed the \nconverse? That at least needs some\nexplanation.\"\nI don't really know the answer to that one. The idea that computer\nsimulations could be the real thing ought to \nhave seemed suspicious in\nthe first place because the computer isn't confined to simulating\nmental operations, by \nany means. No one supposes that computer\nsimulations of a five-alarm fire will burn the neighborhood down or\nthat a computer simulation of a rainstorm will leave us all drenched.\nWhy on earth would anyone suppose that a \ncomputer simulation of\nunderstanding actually understood anything? It is sometimes said that\nit would be \nfrightfully hard to get computers to feel pain or fall in","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":12,"lines":{"from":67,"to":88}}}}],["dd024c35-69c7-4903-a7e0-7b00a2f5f335",{"pageContent":"computer simulation of\nunderstanding actually understood anything? It is sometimes said that\nit would be \nfrightfully hard to get computers to feel pain or fall in\nlove, but love and pain are neither harder nor easier than \ncognition or\nanything else. For simulation, all you need is the right input and\noutput and a program in the middle \nthat transforms the former into the\nlatter. That is all the computer has for anything it does. To confuse\nsimulation \nwith duplication is the same mistake, whether it is pain,\nlove, cognition, fires, or rainstorms.\nStill, there are several reasons why AI must have seemed and to many\npeople perhaps still does seem -- in \nsome way to reproduce and thereby\nexplain mental phenomena, and I believe.we will not succeed in removing\nthese illusions until we have fully exposed the reasons that give rise\nto them.\n7/14/03 6:14 PM\nMinds, Brains, and Programs\nPage 12 of 19\nhttp://www.bbsonline.org/documents/a/00/00/04/84/bbs00000484-00/bbs.searle2.html","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":12,"lines":{"from":88,"to":110}}}}],["5d7060a5-1a30-4837-b0cb-1e16523393bd",{"pageContent":"First, and perhaps most important, is a confusion about the notion of\ninformation processing: many people in \ncognitive science believe that\nthe human brain, with its mind, does something called -information\nprocessing,\" \nand analogously the computer with its program does\ninformation processing; but fires and rainstorms, on the \nother hand,\ndon't do information processing at all. Thus, though the computer can\nsimulate the formal features \nof any process whatever, it stands in a\nspecial relation to the mind and brain because when the computer is\nproperly programmed, ideally with the same program as the brain, the\ninformation processing is identical in the \ntwo cases, and this\ninformation processing is really the essence of the mental. \nBut the trouble with this argument is that it rests on an ambiguity in\nthe notion of '- information.\" In the sense in \nwhich people \"process\ninformation\" when they reflect, say, on problems in arithmetic or when\nthey read and","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":13,"lines":{"from":1,"to":21}}}}],["d44987ef-434a-4c66-82b0-ae476c03fb77",{"pageContent":"the notion of '- information.\" In the sense in \nwhich people \"process\ninformation\" when they reflect, say, on problems in arithmetic or when\nthey read and \nanswer questions about stories, the programmed computer\ndoes not do -information processing.\" Rather, what \nit does is\nmanipulate formal symbols. The fact that the programmer and the\ninterpreter of the computer output \nuse the symbols to stand for objects\nin the world is totally beyond the scope of the computer. The computer,\nto \nrepeat, has a syntax but no semantics. Thus, if you type into the\ncomputer '2 plus 2 equals?\" it will type out '-4.\" \nBut it has no idea\nthat -4\" means 4 or that it means anything at all. And the point is not\nthat it lacks some \nsecond-order information about the interpretation of\nits first- order symbols, but rather that its first-order \nsymbols don't\nhave any interpretations as far as the computer is concerned. All the\ncomputer has is more \nsymbols.","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":13,"lines":{"from":21,"to":43}}}}],["0bd0ae5c-858c-49b8-8c2d-50dba8c12cd4",{"pageContent":"its first- order symbols, but rather that its first-order \nsymbols don't\nhave any interpretations as far as the computer is concerned. All the\ncomputer has is more \nsymbols. \nThe introduction of the notion of \"information processing\" therefore\nproduces a dilemma: either we construe the \nnotion of \"information\nprocessing\" in such a way that it implies intentionality as part of the\nprocess or we don't. If \nthe former, then the programmed computer does\nnot do information processing, it only manipulates formal \nsymbols. If\nthe latter, then, though the computer does information processing, it\nis only doing so in the sense in \nwhich adding machines, typewriters,\nstomachs, thermostats, rainstorms, and hurricanes do information\nprocessing; namely, they have a level of description at which we can\ndescribe them as taking information in at \none end, transforming it, and\nproducing information as output. But in this case it is up to outside\nobservers to","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":13,"lines":{"from":43,"to":64}}}}],["2787fb91-7a2e-4ce2-a39d-d28a9fef8536",{"pageContent":"describe them as taking information in at \none end, transforming it, and\nproducing information as output. But in this case it is up to outside\nobservers to \ninterpret the input and output as information in the\nordinary sense. And no similarity is established between the \ncomputer\nand the brain in terms of any similarity of information processing.\nSecond, in much of AI there is a residual behaviorism or\noperationalism. Since appropriately programmed \ncomputers can have\ninput-output patterns similar to those of human beings, we are tempted\nto postulate mental \nstates in the computer similar to human mental\nstates. But once we see that it is both conceptually and \nempirically\npossible for a system to have human capacities in some realm without\nhaving any intentionality at all, \nwe should be able to overcome this\nimpulse. My desk adding machine has calculating capacities, but no\nintentionality, and in this paper I have tried to show that a system","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":13,"lines":{"from":64,"to":84}}}}],["174d948f-6e37-4ee2-ba4c-2cbcb1d78f7e",{"pageContent":"we should be able to overcome this\nimpulse. My desk adding machine has calculating capacities, but no\nintentionality, and in this paper I have tried to show that a system\ncould have input and output capabilities that \nduplicated those of a\nnative Chinese speaker and still not understand Chinese, regardless of\nhow it was \nprogrammed. The Turing test is typical of the tradition in\nbeing unashamedly behavioristic and operationalistic, \nand I believe\nthat if AI workers totally repudiated behaviorism and operationalism\nmuch of the confusion \nbetween simulation and duplication would be\neliminated.\nThird, this residual operationalism is joined to a residual form of\ndualism; indeed strong AI only makes sense \ngiven the dualistic\nassumption that, where the mind is concerned, the brain doesn't matter.\nIn strong AI (and in \nfunctionalism, as well) what matters are programs,\nand programs are independent of their realization in \nmachines; indeed,","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":13,"lines":{"from":84,"to":105}}}}],["c9783591-d3b1-4be5-a845-3335f3edff19",{"pageContent":"In strong AI (and in \nfunctionalism, as well) what matters are programs,\nand programs are independent of their realization in \nmachines; indeed,\nas far as AI is concerned, the same program could be realized by an\nelectronic machine, a \nCartesian mental substance, or a Hegelian world\nspirit. The single most surprising discovery that I have made in\ndiscussing these issues is that many AI workers are quite shocked by my\nidea that actual human mental \nphenomena might be dependent on actual\nphysical/chemical properties of actual human brains.\nBut if you think about it a minute you can see that I should not have\nbeen surprised; for unless you accept some \n7/14/03 6:14 PM\nMinds, Brains, and Programs\nPage 13 of 19\nhttp://www.bbsonline.org/documents/a/00/00/04/84/bbs00000484-00/bbs.searle2.html","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":13,"lines":{"from":105,"to":122}}}}],["d6133048-6062-4de1-b18c-4d4ee661f851",{"pageContent":"form of dualism, the strong\nAI project hasn't got a chance. The project is to reproduce and explain\nthe mental \nby designing programs, but unless the mind is not only\nconceptually but empirically independent of the brain you \ncouldn't\ncarry out the project, for the program is completely independent of any\nrealization. Unless you believe \nthat the mind is separable from the\nbrain both conceptually and empirically -- dualism in a strong form --\nyou \ncannot hope to reproduce the mental by writing and running programs\nsince programs must be independent of \nbrains or any other particular\nforms of instantiation. If mental operations consist in computational\noperations on \nformal symbols, then it follows that they have no\ninteresting connection with the brain; the only connection \nwould be\nthat the brain just happens to be one of the indefinitely many types of\nmachines capable of instantiating \nthe program. \nThis form of dualism is not the traditional Cartesian variety that","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":14,"lines":{"from":1,"to":23}}}}],["4e55f9aa-f4b2-42ab-9887-48c669759b74",{"pageContent":"would be\nthat the brain just happens to be one of the indefinitely many types of\nmachines capable of instantiating \nthe program. \nThis form of dualism is not the traditional Cartesian variety that\nclaims there are two sorts of substances, but it \nis Cartesian in the\nsense that it insists that what is specifically mental about the mind\nhas no intrinsic connection \nwith the actual properties of the brain.\nThis underlying dualism is masked from us by the fact that AI\nliterature \ncontains frequent fulminations against \"dualism'-; what the\nauthors seem to be unaware of is that their position \npresupposes a\nstrong version of dualism.\n\"Could a machine think?\" My own view is that only a machine could\nthink, and indeed only very special kinds \nof machines, namely brains\nand machines that had the same causal powers as brains. And that is\nthe main \nreason strong AI has had little to tell us about thinking,\nsince it has nothing to tell us about machines. By its own \ndefinition,","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":14,"lines":{"from":23,"to":46}}}}],["0ad4c65b-3097-46d5-9171-a87863d35900",{"pageContent":"the main \nreason strong AI has had little to tell us about thinking,\nsince it has nothing to tell us about machines. By its own \ndefinition,\nit is about programs, and programs are not machines. Whatever else\nintentionality is, it is a biological \nphenomenon, and it is as likely\nto be as causally dependent on the specific biochemistry of its origins\nas \nlactation, photosynthesis, or any other biological phenomena. No one\nwould suppose that we could produce \nmilk and sugar by running a\ncomputer simulation of the formal sequences in lactation and\nphotosynthesis, but \nwhere the mind is concerned many people are\nwilling to believe in such a miracle because of a deep and abiding\ndualism: the mind they suppose is a matter of formal processes and is\nindependent of quite specific material \ncauses in the way that milk and\nsugar are not.\nIn defense of this dualism the hope is often expressed that the brain\nis a digital computer (early computers, by \nthe way, were often called","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":14,"lines":{"from":46,"to":68}}}}],["b6acee1e-fed7-4e40-b1ab-eabc3a36c8c3",{"pageContent":"causes in the way that milk and\nsugar are not.\nIn defense of this dualism the hope is often expressed that the brain\nis a digital computer (early computers, by \nthe way, were often called\n\"electronic brains\"). But that is no help. Of course the brain is a\ndigital computer. \nSince everything is a digital computer, brains are\ntoo. The point is that the brain's causal capacity to produce\nintentionality cannot consist in its instantiating a computer program,\nsince for any program you like it is possible \nfor something to\ninstantiate that program and still not have any mental states. Whatever\nit is that the brain does \nto produce intentionality, it cannot consist\nin instantiating a program since no program, by itself, is sufficient\nfor \nintentionality.\nACKNOWLEDGMENT\nI am indebted to a rather large number of people for\ndiscussion of these matters and for their patient attempts \nto overcome\nmy ignorance of artificial intelligence. I would especially like to\nthank Ned Block, Hubert Dreyfus,","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":14,"lines":{"from":68,"to":91}}}}],["568dbe9d-812d-4436-9445-1fe8a1f6db92",{"pageContent":"discussion of these matters and for their patient attempts \nto overcome\nmy ignorance of artificial intelligence. I would especially like to\nthank Ned Block, Hubert Dreyfus, \nJohn Haugeland, Roger Schank, Robert\nWilensky, and Terry Winograd.\nNOTES\n1.\nI am not, of course, saying that Schank himself is committed to these\nclaims.\n2.\nAlso, \"understanding\" implies both the possession of mental\n(intentional) states and the truth (validity, \nsuccess) of these states\nFor the purposes of this discussion we are concerned only with the\npossession of \nthe states.\n7/14/03 6:14 PM\nMinds, Brains, and Programs\nPage 14 of 19\nhttp://www.bbsonline.org/documents/a/00/00/04/84/bbs00000484-00/bbs.searle2.html","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":14,"lines":{"from":91,"to":111}}}}],["b2250e7b-d8e7-420b-9916-a8950e367b3d",{"pageContent":"3.\nIntentionality is by definition that feature of certain mental\nstates by which they are directed at or about \nobjects and states of\naffairs in the world. Thus, beliefs, desires, and intentions are\nintentional states; \nundirected forms of anxiety and depression are not.\nFor further discussion see Searle (1979c).\nREFERENCES\nAnderson, J. (1980) Cognitive units. Paper presented at the Society for\nPhilosophy and Psychology, Ann \nArbor, Mich. [RCS]\nBlock, N. J. (1978) Troubles with functionalism. In: Minnesota studies\nin the philosophy of science, vol. 9, ed. \nC. W. Savage, Minneapolis:\nUniversity of Minnesota Press. [NB, WGL]\n(forthcoming) Psychologism and behaviorism. Philosophical Review. [NB,\nWGL]\nBower, G. H.; Black, J. B., & Turner, T. J. (1979) Scripts in text\ncomprehension and memory. Cognition \nPsychology 11:177-220. [RCS]\nCarroll, C. W. (1975) The great chess automaton. New York: Dover. [RP]\nCummins, R. (1977) Programs in the explanation of behavior. Philosophy","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":15,"lines":{"from":1,"to":23}}}}],["63603524-2bed-4e3b-9641-60fdb44bd544",{"pageContent":"Psychology 11:177-220. [RCS]\nCarroll, C. W. (1975) The great chess automaton. New York: Dover. [RP]\nCummins, R. (1977) Programs in the explanation of behavior. Philosophy\nof Science 44: 269-87. UCM]\nDennett, D. C. (1969) Content and consciousness. London: Routledge &\nKegan Paul. [DD,TN]\n______. (1971) Intentional systems Journal of Philosophy 68: 87-106.\n[TN]\n______. (1972) Reply to Arbib and Gunderson. Paper presented at the\nEastern Division meeting of the \nAmerican Philosophical Association.\nBoston, Mass. [TN]\n______. (1975) Why the law of effect won't go away. Journal for the\nTheory of Social Behavior 5:169-87. \n[NB]\n______. (1978) Brainstorms. Montgomery, Vt,: Bradford Books. [DD, AS]\nEccles, J. C. (1978) A critical appraisal of brain-mind theories. In:\nCerebral correlates of conscious \nexperiences, ed. P. A. Buser and A.\nRougeul-Buser, pp. 347 55. Amsterdam: North Holland. [JCE]\n______. (1979) The human mystery. Heidelberg: Springer Verlag. UCE]","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":15,"lines":{"from":23,"to":43}}}}],["f22ddd59-1a78-4b24-a41a-10f04aafa2ca",{"pageContent":"Cerebral correlates of conscious \nexperiences, ed. P. A. Buser and A.\nRougeul-Buser, pp. 347 55. Amsterdam: North Holland. [JCE]\n______. (1979) The human mystery. Heidelberg: Springer Verlag. UCE]\nFodor, J. A. (1968) The appeal to tacit knowledge in psychological\nexplanation. Journal of Philoso phy 65: \n627-40. [NB]\n______. (1980) Methodological solipsism considered as a research\nstrategy in cognitive psychology. The \nBehavioral and Brain S^ciences\n3:1. [NB, WGL, WES]\nFreud, S. (1895) Project for a scientific psychology. In: The standard\nedition of the complete psychological \nworks of Sigmund Freud, vol. 1,\ned. J. Strachey. London: Hogarth Press, 1966. UCM]\n7/14/03 6:14 PM\nMinds, Brains, and Programs\nPage 15 of 19\nhttp://www.bbsonline.org/documents/a/00/00/04/84/bbs00000484-00/bbs.searle2.html","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":15,"lines":{"from":43,"to":61}}}}],["88ce2c8e-d98c-4457-8a14-e7a939fb9ebd",{"pageContent":"Frey, P. W. (1977) An introduction to computer chess. In: Chess skill in\nman and machine, ed. P. W. Frey. \nNew York, Heidelberg, Berlin:\nSpringer Verlag. [RP]\nFryer, D. M. & Marshall, J. C. (1979) The motives of Jacques de\nVaucanson. Technology and Culture 20: \n257-69. [JCM]\nGibson, J. J. (1976) The senses considered as perceptual systems.\nBoston: Houghton Mifflin. [TN]\n______. (1967) New reasons for realism. Synthese 17: 162-72. [TN]\n______. (1972) A theory of direct visual perception. In: The psychology\nof knowing ed. S. R. Royce & W. \nW. Rozeboom. New York: Gordon &\nBreach. [TN]\nGraesser, A. C.; Gordon, S. E.; & Sawyer, J. D. (1979) Recognition\nmemory for typical and atypical actions \nin scripted activities: tests\nfor a script pointer and tag hypotheses. Journal of Verbal Learning\nand Verbal \nBehavior 1: 319-32. [RCS]\nCruendel, J. (1980). Scripts and stories: a study of children's event\nnarratives. Ph.D. dissertation, Yale \nUniversity. [RCS]","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":16,"lines":{"from":1,"to":23}}}}],["7b5398af-7ecb-4023-a547-b02352547b36",{"pageContent":"and Verbal \nBehavior 1: 319-32. [RCS]\nCruendel, J. (1980). Scripts and stories: a study of children's event\nnarratives. Ph.D. dissertation, Yale \nUniversity. [RCS]\nHanson, N. R. (1969) Perception and discovery. San Francisco: Freeman,\nCooper. [DOW]\nHayes, P. J. (1977) In defence of logic. In: Proceedings of the 5th\ninternational joint conference on artificial \nintelligence, ed. R. Reddy.\nCambridge, Mass.: M.l.T. Press. [WES]\nHobbes, T. (1651) Leviathan. London: Willis. UCM]\nHofstadter, D. R. (1979) Goedel, Escher, Bach. New York: Basic\nBooks. [DOW]\nHouseholder, F. W. (1962) On the uniqueness of semantic mapping. Word\n18: 173-85. UCM]\nHuxley, T. H. (1874) On the hypothesis that animals are automata and\nits history. In: Collected Essays, vol. 1. \nLondon: Macmillan, 1893.\nUCM]\nKolers, P. A. & Smythe, W. E. (1979) Images, symbols, and skills.\nCanadian Journal of Psychology 33: 158 \n84. [WES]\nKosslyn, S. M. & Shwartz, S. P. (1977) A simulation of visual imagery.","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":16,"lines":{"from":23,"to":46}}}}],["9ede1a8b-cdd2-491f-b5d0-7c60a9d3b199",{"pageContent":"UCM]\nKolers, P. A. & Smythe, W. E. (1979) Images, symbols, and skills.\nCanadian Journal of Psychology 33: 158 \n84. [WES]\nKosslyn, S. M. & Shwartz, S. P. (1977) A simulation of visual imagery.\nCognitive Science 1: 265-95. [WES]\nLenneberg, E. H. (1975) A neuropsychological comparison between man,\nchimpanzee\nand monkey. Neuropsychologia 13: 125. [JCE]\nLibet, B. (1973) Electrical stimulation of cortex in human subjects and\nconscious sensory aspects. In: \nHandbook of sensory physiology, vol. 11,\ned. A. Iggo, pp. 74S 90. New York: Springer-Verlag. [BL]\nLibet, B., Wright, E. W., Jr., Feinstein, B., and Pearl, D. K. (1979)\nSubjective referral of the timing for a \n7/14/03 6:14 PM\nMinds, Brains, and Programs\nPage 16 of 19\nhttp://www.bbsonline.org/documents/a/00/00/04/84/bbs00000484-00/bbs.searle2.html","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":16,"lines":{"from":46,"to":64}}}}],["f3b92e0f-43c0-497e-bb1a-b2a1b5bc5c10",{"pageContent":"conscious sensory experience: a\nfunctional role for the somatosensory specific projection system in\nman. Brain \n102:191222. [BL]\nLonguet-Higgins, H. C. (1979) The perception of music. Proceedings of\nthe Royal Society of London B \n205:307-22. [JCM]\nLucas, J. R. (1961) Minds, machines, and Godel. Philosophy 36:112127.\n[DRH]\nLycan, W. G. (forthcoming) Form, function, and feel. Journal of\nPhilosophy [NB, WGL]\nMcCarthy, J. (1979) Ascribing mental qualities to machines. In:\nPhilosophical perspectives in artificial \nintelligence, ed. M. Ringle.\nAtlantic Highlands, N.J.: Humanities Press. UM, JRS]\nMarr, D. & Poggio, T. (1979) A computational theory of human stereo\nvision. Proceedings of the Royal \nSociety of London B 204:301-28. UCM]\nMarshall, J. C. (1971) Can humans talk? In: Biological and social\nfactors in psycholinguistics, ed. J. Morton. \nLondon: Logos Press. [JCM]\n______. (1977) Minds, machines and metaphors. Social Studies of Science\n7:47588. [JCM]","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":17,"lines":{"from":1,"to":23}}}}],["5a3896f9-8bc6-43d3-96c3-92937c83c302",{"pageContent":"factors in psycholinguistics, ed. J. Morton. \nLondon: Logos Press. [JCM]\n______. (1977) Minds, machines and metaphors. Social Studies of Science\n7:47588. [JCM]\nMaxwell, G. (1976) Scientific results and the mind-brain issue. In:\nConsciousness and the brain, ed. G. G. \nGlobus, G. Maxwell, & 1.\nSavodnik. New York: Plenum Press. [GM]\n______. (1978) Rigid designators and mind-brain identity. In:\nPerception and cognition: Issues in the \nfoundations of psychology,\nMinnesota Studies in the Philosophy of Science, vol. 9, ed. C. W.\nSavage. \nMinneapolis: University of Minnesota Press. [GM]\nMersenne, M. (1636) Harmonie universelle Paris: Le Gras. UCM]\nMoor, J. H. (1978) Three myths of computer science. British Journal of\nthe Philosophy of Science 29:213-22. \nUCM]\nNagel, T. (1974) What is it like to be a bat? Philosophical Review\n83:43550. [GM]\nNatsoulas, T. (1974) The subjective, experiential element in\nperception. Psychological Bulletin 81:611-31. \n[TN]","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":17,"lines":{"from":23,"to":45}}}}],["1d5f888b-c054-4386-bb56-08b854efc26a",{"pageContent":"UCM]\nNagel, T. (1974) What is it like to be a bat? Philosophical Review\n83:43550. [GM]\nNatsoulas, T. (1974) The subjective, experiential element in\nperception. Psychological Bulletin 81:611-31. \n[TN]\n______. (1977) On perceptual aboutness. Behaviorism 5:75-97. [TN]\n______. (1978a) Haugeland's first hurdle. Behavioral and Brain Sciences\n1:243. [TN]\n______. (1979b) Residual subjectivity. American Psychologist 33:269-83.\n[TN]\n______. (1980) Dimensions of perceptual awareness. Psychology\nDepartment, University of California, Davis. \nUnpublished manuscript.\n[TN]\n7/14/03 6:14 PM\nMinds, Brains, and Programs\nPage 17 of 19\nhttp://www.bbsonline.org/documents/a/00/00/04/84/bbs00000484-00/bbs.searle2.html","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":17,"lines":{"from":45,"to":63}}}}],["6df803b0-de3d-4b32-aa5f-208ccaab8376",{"pageContent":"Nelson, K. & Gruendel, J. (1978) From person episode to social script:\ntwo dimensions in the development of \nevent knowledge. Paper presented\nat the biennial meeting of the Society for Research in Child\nDevelopment, \nSan Francisco. [RCS]\nNewell, A. (1973) Production systems: models of control structures. In:\nVisual information processing, ed. W. \nC. Chase. New York: Academic\nPress. [WES]\n( 1979) Physical symbol systems. Lecture t the La Jolla Conference on\nCognitive Science. URS]\n______. (1980) Harpy, production systems, and human cognition. In:\nPerception and production of fluent \nspeech, ed. R. Cole. Hillsdale,\nN.J.: Erlbaum Press. [WES]\nNewell, A. & Simon, H. A. (1963) GPS, a program that simulates human\nthought. In: Computers and thought, \ned. A. Feigenbaum & V. Feldman,\npp. 279-93. New York: McGraw Hill. JRS]\nPanofsky, E. (1954) Galileo as a critic of the arts. The Hague:\nMartinus Nijhoff. UCM]\nPopper, K. R. & Eccles, J. C. (1977) The self and its brain.","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":18,"lines":{"from":1,"to":23}}}}],["bff95e1a-405a-4182-8961-dae5fcae963f",{"pageContent":"pp. 279-93. New York: McGraw Hill. JRS]\nPanofsky, E. (1954) Galileo as a critic of the arts. The Hague:\nMartinus Nijhoff. UCM]\nPopper, K. R. & Eccles, J. C. (1977) The self and its brain.\nHeidelberg: Springer-Verlag. UCE, GM]\nPutnam, H. (1960) Minds and machines. In Dimensions of mind, ed. S.\nHook, pp. 138 64. New York: Collier. \n[MR, RR]\n______. (1975a) The meaning of ''meaning.\" In: Mind, language and\nreality Cambridge University Press. [NB, \nWGL]\n______. (1975b) The nature of mental states. In: Mind, language and\nreality Cambridge: Cambridge University \nPress. [NB]\n______. (1975c) Philosophy and our mental life In: Mind, language and\nreality Cambridge: Cambridge \nUniversity Press. [MM]\nPylyshyn, Z. W. (1980a) Computation and cognition: issues in the\nfoundations of cognitive science. Behavioral \nand Brain Sciences 3.\n[JRS, WES]\n______. (1980b) Cognitive representation and the process-architecture\ndistinction. Behavioral and Brain \nSciences [ZWP]","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":18,"lines":{"from":23,"to":46}}}}],["3e9f6b47-9d06-4000-91e2-b3b02ce4923f",{"pageContent":"foundations of cognitive science. Behavioral \nand Brain Sciences 3.\n[JRS, WES]\n______. (1980b) Cognitive representation and the process-architecture\ndistinction. Behavioral and Brain \nSciences [ZWP]\nRussell, B. (1948) Human knowledge: its scope and limits New York:\nSimon and Schuster. [GM]\nSchank, R. C. & Abelson, R. P. (1977) Scripts, plans, goals, and\nunderstanding Hillsdale, N.J.: Lawrence \nErlbaum Press. [RCS, JRS]\nSearle, J. R. (1979a) Intentionality and the use of language. In:\nMeaning and use, ed. A. Margalit. Dordrecht: \nReidel. [TN, JRS]\n______. (1979b) The intentionality of intention and action. Inquiry\n22:25380. [TN, JRS]\n______. (1979c) What is an intentional state? Mind 88:74-92. UH, GM,\nTN, JRS]\n7/14/03 6:14 PM\nMinds, Brains, and Programs\nPage 18 of 19\nhttp://www.bbsonline.org/documents/a/00/00/04/84/bbs00000484-00/bbs.searle2.html","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":18,"lines":{"from":46,"to":67}}}}],["fcee7107-b29c-43ac-ba10-8cd713cf9f8a",{"pageContent":"Sherrington, C. S. (1950) Introductory. In: The physical basis of mind,\ned. P. Laslett, Oxford: Basil Blackwell. \n[JCE]\nSlate, J. S. & Atkin, L. R. (1977) CHESS 4.5 - the Northwestern\nUniversity chess program. In: Chess skill in \nman and machine, ed. P. W.\nFrey. New York, Heidelberg, Berlin: Springer Verlag. Sloman, A. (1978)\nThe \ncomputer resolution in phylosophy Harvester Press and Humanities\nPress. [AS]\n______. (1979) The primacy of non-communicative language. In: The\nanalysis of meaning (informatics s)> ed. \nM. McCafferty & K. Gray.\nLondon: ASLIB and British Computer Society. [AS]\nSmith, E. E.; Adams, N.; & Schorr, D. (1978) Fact retrieval and the\nparadox of interference. Cognition \nPsychology 10:438-64. [RCS]\nSmythe, W. E. (1979) The analogical/propositional debate about mental\nrep representation: a Goodmanian \nanalysis Paper presented at the 5th annual\nmeeting of the Society for Philosophy and Psychology, New York \nCity.\n[WES]","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":19,"lines":{"from":1,"to":23}}}}],["1a1680ec-5b8f-41f0-a013-ea10ef8aefac",{"pageContent":"rep representation: a Goodmanian \nanalysis Paper presented at the 5th annual\nmeeting of the Society for Philosophy and Psychology, New York \nCity.\n[WES]\nSperry, R. W. (1969) A modified concept of consciousness. Psychological\nReview 76:532-36. [TN]\n______. (1970) An objective approach to subjective experience: further\nexplanation of a hypothesis. \nPsychological Review 77:585-90. [TN]\n______. (1976) Mental phenomena as causal determinants in brain\nfunction. In: Consciousness and the brain, \ned. G. G. Globus, G.\nMaxwell, & 1. Savodnik. New York: Plenum Press. [TN]\nStich, S. P. (in preparation) On the ascription of content. In:\nEntertaining thoughts, ed. A. Woodfield. [WGL]\nThorne, J. P. (1968) A computer model for the perception of syntactic\nstructure. Proceedings of the Royal \nSociety of London B 171:37786.\nUCM]\nTuring, A. M. (1964) Computing machinery and intelligence. In: Minds\nand machines, ed. A. R. Anderson, \npp.4-30. Englewood Cliffs, N.J.:\nPrentice Hall. [MR]","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":19,"lines":{"from":23,"to":46}}}}],["fc397402-fd9b-4f91-bef3-c1692cced3db",{"pageContent":"Society of London B 171:37786.\nUCM]\nTuring, A. M. (1964) Computing machinery and intelligence. In: Minds\nand machines, ed. A. R. Anderson, \npp.4-30. Englewood Cliffs, N.J.:\nPrentice Hall. [MR]\nWeizenbaum, J. (1965) Eliza - a computer program for the study of\nnatural language communication between \nman and machine. Communication\nof the Association for Computing Machinery 9:36 45. [JRS]\n( 1976) Computer power and human reason San Francisco: W. H. Freeman.\nURS]\nWinograd, T. (1973) A procedural model of language understanding. In:\nComputer models of thought and \nlanguage, ed. R. Schank & K. Colby. San\nFrancisco: W. H. Freeman. [JRS]\nWinston, P. H. (1977) Artificial intelligence Reading, Mass. Addison-\nWesley; JRS]\nWoodruff, G. & Premack, D. (1979) Intentional communication in the\nchimpanzee: the development of \ndeception. Cognition 7:333-62. [JCM]\n7/14/03 6:14 PM\nMinds, Brains, and Programs\nPage 19 of 19\nhttp://www.bbsonline.org/documents/a/00/00/04/84/bbs00000484-00/bbs.searle2.html","metadata":{"source":"10.1.1.83.5248.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.1","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"","Author":"Jon Slemmer","Subject":"","Keywords":"","Creator":"Internet Explorer","Producer":"Acrobat PDFWriter 3.0.1 for Power Macintosh","CreationDate":"D:20030714181421"},"metadata":null,"totalPages":19},"loc":{"pageNumber":19,"lines":{"from":46,"to":70}}}}]],{"0":"98905345-65ee-4831-bc32-689ca5ff525c","1":"8d793fdf-8a12-48ed-9eaf-2713cd80e442","2":"7eb2523c-1cfc-48ac-ab16-9ebc7f7d84c0","3":"63e259a1-aa58-4180-ba87-d4e106eff705","4":"cee7e636-2b11-4ed6-86ab-e02b5730f5ad","5":"b4e8a985-c6e5-4c1e-abde-f54274e640c6","6":"fba20dbb-8340-496d-882c-61590936dd75","7":"c9c358b9-3f48-4196-8065-32f0d091aa2e","8":"5c278deb-ddce-439d-80bc-89a8bb7f7ac7","9":"57068be2-f86c-4547-8e2c-fe04579b901b","10":"a38db9bb-5197-4bd7-a8cb-8a22b7950cae","11":"999e65ec-a923-45cc-81ad-c9ccf7c285cb","12":"f945b853-22cd-40bc-a48d-e6af7397bee6","13":"e5b9d2e3-af04-4576-ba8f-df7e314b85e6","14":"bc09bb2f-09f0-4b24-859f-6b1aec74990e","15":"0c3696c3-1292-45bd-851c-931c93309078","16":"b4aac1f3-87c3-439c-92f4-ef191ae85d1a","17":"f6aac13d-b5e8-44b2-89b8-b51ec0ac5039","18":"0c23e0a0-108c-48e6-8255-35d0e18fb9c2","19":"fd84b751-4bc9-433b-b10f-0106af807f7e","20":"e2b10f0b-5133-4603-a942-5373ef8b92d2","21":"d8269292-5f3c-409a-b3a5-9844ca8641d0","22":"53b629b1-1577-40f2-8480-ef696f04983c","23":"d31deca4-bc4d-4962-9c83-b31d5e9f63e6","24":"b234fe66-1028-449b-95f8-39e12970bdb0","25":"5a139fe3-75b6-4d9f-b2cd-b330a501be66","26":"bfa99cf3-75d9-4580-a79f-cede4973e359","27":"83391a0f-ade0-484e-92ca-7087743b8b25","28":"ee528bdd-199b-4472-8285-57ee046d3733","29":"67ff5dc5-efb1-4b35-9cb7-f0cab6738b0c","30":"cf35ae71-771b-4952-90ac-109ab1c5f6ea","31":"b3763238-769a-46cb-9c9f-8b996cb8b066","32":"f4057c73-a4f2-4623-9359-6928f550f6d9","33":"6a7b6fa8-ba5d-4cdc-804c-adfcddd856e8","34":"3ff8a562-ad77-471d-ade5-d01f06941343","35":"2a5d9417-726a-4bae-a9a1-171181232b9e","36":"ab507bc0-920b-42b1-97db-211960da201d","37":"b40b37d2-46ab-4c50-95b4-432534f563a5","38":"92f16137-05e3-4001-b5d6-2f29a20088ca","39":"b42cb937-67f1-4bad-808b-6977dc754761","40":"2b086743-2906-4f42-9086-840b3ec74e6e","41":"19f85a5f-d964-4b1d-ba86-d09683ec5256","42":"933760d9-52a1-4dd6-b52a-6eeaad31dfe2","43":"dd1d3295-7f7f-40e8-87a7-282b012ff64a","44":"17e26113-2e89-4317-85b6-5bbe420e041f","45":"668d8b75-d791-4413-8847-9e5a05676deb","46":"90ebfa2f-b474-40c4-b21f-c4a17350dffe","47":"55fa8823-a923-428c-b796-93324e6dce87","48":"a290985a-58b2-4688-aa41-3eebdee65342","49":"8d92b6e0-d61c-4876-b375-d90424913d2c","50":"bc6e19d1-568f-46b6-9c0f-e3d077b06fb6","51":"d2564fd8-0d14-4b35-aa51-69bf0d0b20ab","52":"ffe6f862-a82a-4481-a144-e8fd39f78f66","53":"75ae13a1-300d-422f-8b6a-d0f1df930a4e","54":"a9ea1661-76ee-4f57-a41a-5cdbbe655f18","55":"705ee9ed-edba-432d-9a38-a50e9e36ba10","56":"af7df7cb-c8f6-4bf9-8663-c035a4478298","57":"39763ac5-0c50-44ea-a93d-b60194e755e8","58":"82cfefa5-64de-42f9-a933-b0be7eb5726e","59":"1e4e7096-a22c-43fc-8fae-89b1bc313276","60":"fd83b3da-74fe-4acd-b30a-0b6a5ca1d45b","61":"9c6f8db5-24d0-46d6-9806-073a6753fe8b","62":"338812a7-54cb-45fb-a6e0-7c93d24fba50","63":"97cc6803-0d4a-432a-ae9d-89b38c115b7d","64":"35c87cc9-cab7-4646-a3f0-58222bd15274","65":"4a451990-a1de-4a51-8076-9976a64a2ca8","66":"95e0109e-c922-435c-a96b-59e96f2f61a1","67":"dd024c35-69c7-4903-a7e0-7b00a2f5f335","68":"5d7060a5-1a30-4837-b0cb-1e16523393bd","69":"d44987ef-434a-4c66-82b0-ae476c03fb77","70":"0bd0ae5c-858c-49b8-8c2d-50dba8c12cd4","71":"2787fb91-7a2e-4ce2-a39d-d28a9fef8536","72":"174d948f-6e37-4ee2-ba4c-2cbcb1d78f7e","73":"c9783591-d3b1-4be5-a845-3335f3edff19","74":"d6133048-6062-4de1-b18c-4d4ee661f851","75":"4e55f9aa-f4b2-42ab-9887-48c669759b74","76":"0ad4c65b-3097-46d5-9171-a87863d35900","77":"b6acee1e-fed7-4e40-b1ab-eabc3a36c8c3","78":"568dbe9d-812d-4436-9445-1fe8a1f6db92","79":"b2250e7b-d8e7-420b-9916-a8950e367b3d","80":"63603524-2bed-4e3b-9641-60fdb44bd544","81":"f22ddd59-1a78-4b24-a41a-10f04aafa2ca","82":"88ce2c8e-d98c-4457-8a14-e7a939fb9ebd","83":"7b5398af-7ecb-4023-a547-b02352547b36","84":"9ede1a8b-cdd2-491f-b5d0-7c60a9d3b199","85":"f3b92e0f-43c0-497e-bb1a-b2a1b5bc5c10","86":"5a3896f9-8bc6-43d3-96c3-92937c83c302","87":"1d5f888b-c054-4386-bb56-08b854efc26a","88":"6df803b0-de3d-4b32-aa5f-208ccaab8376","89":"bff95e1a-405a-4182-8961-dae5fcae963f","90":"3e9f6b47-9d06-4000-91e2-b3b02ce4923f","91":"fcee7107-b29c-43ac-ba10-8cd713cf9f8a","92":"1a1680ec-5b8f-41f0-a013-ea10ef8aefac","93":"fc397402-fd9b-4f91-bef3-c1692cced3db"}]